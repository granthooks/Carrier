# Carrier Project Intelligence

This file serves as a learning journal for the Carrier project, capturing important patterns, preferences, and project intelligence that help work more effectively. This document will evolve as we discover and document key insights about the project.

## Project Patterns

### Agent Runtime Loop Pattern
The core pattern for the Carrier project is the 7-step runtime loop:
1. **Initialization**: Set up the agent with personality, actions, providers, services
2. **Message Reception**: Receive messages from various clients
3. **Message Processing**: Process through decision pipeline
4. **Response Generation**: Generate responses using LLMs
5. **Action Execution**: Execute any needed actions
6. **Evaluation**: Assess response quality
7. **Memory Storage**: Store interactions for context

This pattern is the foundation of the agent architecture and is now implemented in both discord_agent.py and tifa_agent.py through runtime hooks and the Agent/Runner classes.

### Runtime Hooks Implementation Pattern
The Carrier framework uses a hooks pattern to implement the runtime loop stages:
```python
class DiscordHooks(RunHooks):
    async def on_agent_start(self, context, agent) -> None:
        # Step 3: Message Processing pipeline begins
        
    async def on_tool_start(self, context, agent, tool) -> None:
        # Step 5: Action Execution begins
        
    async def on_tool_end(self, context, agent, tool, result) -> None:
        # Step 5: Action Execution completes
        
    async def on_agent_end(self, context, agent, output) -> None:
        # Step 6: Evaluation and Step 7: Memory Storage complete
```

### Component Responsibility Pattern
Each component in the system has clear, single responsibilities:
- **Agent Runtime**: Overall coordination
- **Message Manager**: Message processing
- **State Manager**: Context composition
- **Action Manager**: Tool execution
- **Evaluation System**: Response assessment
- **Memory System**: Interaction storage
- **Provider System**: LLM integration

This separation of concerns ensures that components can evolve independently.

### Async Processing Pattern
The Python implementation leans heavily on async/await:
- Use `asyncio` for concurrent operations
- Implement non-blocking database operations
- Design event-driven message processing

### Memory System Pattern
The memory system follows a layered architecture:
- **Core MemorySystem**: Handles database operations and embedding generation
- **Specialized Memory Managers**: Provide tailored interfaces for different memory types
- **Memory Hooks**: Integrate memory with agent runtime
- **Memory Cache**: Optimizes performance for frequently accessed data

```python
# Core MemorySystem for database operations
class MemorySystem:
    async def store_memory(self, content, memory_type, user_id, room_id, agent_id, metadata=None):
        # Generate embedding and store in database
        
    async def retrieve_similar(self, query, threshold=0.7, limit=10, memory_type=None):
        # Perform vector similarity search
        
# Specialized memory manager for messages
class MessageManager:
    async def create_memory(self, message):
        # Create a message memory
        
    async def get_conversation(self, user_id, room_id, agent_id, limit=20):
        # Get conversation history
        
# Memory hooks for runtime integration
class MemoryContextHooks:
    async def on_agent_start(self, context, agent):
        # Add conversation history to system prompt
```

### Vector Similarity Search Pattern
The memory system uses vector embeddings for semantic search:
- Generate embeddings for all stored memories
- Generate embedding for search query
- Perform vector similarity search using cosine similarity
- Return memories above similarity threshold

```python
# Vector similarity search in PostgreSQL
"""
SELECT
    m.id,
    m.type,
    m.content,
    m.embedding,
    m.user_id,
    m.room_id,
    m.agent_id,
    m.metadata,
    m.created_at,
    1 - (m.embedding <=> $1) as similarity
FROM
    %I.memories m
WHERE
    m.embedding IS NOT NULL AND
    1 - (m.embedding <=> $1) > $2
ORDER BY
    m.embedding <=> $1
LIMIT $3
"""
```

### Memory Manager Pattern
Specialized memory managers for different memory types:
- **MessageManager**: Conversation messages
- **DescriptionManager**: User descriptions
- **LoreManager**: Agent background information
- **DocumentsManager**: Large documents
- **KnowledgeManager**: Searchable knowledge fragments
- **RAGKnowledgeManager**: Retrieval-augmented generation

Each manager extends BaseMemoryManager and provides specialized methods for its memory type.

## User Preferences

### Python Implementation Style
- Use of Pydantic for data validation and type hints
- FastAPI for web endpoints (REST/WebSocket)
- Modern Python features (3.9+) including type hints
- SQLAlchemy for database operations
- Preference for async programming model

### Documentation Approach
- Document architecture decisions thoroughly
- Maintain clear component boundaries
- Use mermaid diagrams for visualizing relationships
- Document data flows between components

### Memory System Preferences
- Supabase for database backend
- PostgreSQL with vector extensions for semantic search
- OpenAI embeddings for vector representation
- Specialized memory managers for different memory types
- Memory hooks for runtime integration
- CLI tools for memory management

## Implementation Paths

### Core Runtime Implementation
1. Define data models with Pydantic
2. Implement database schema
3. Create AgentRuntime class (partially implemented through Agent/Runner classes)
4. Build message processing pipeline (implemented through RunHooks)
5. Implement state composition (partial through AgentMemory)
6. Add response generation (implemented through Runner.run)
7. Set up action execution (tool execution framework started)
8. Add evaluation system (hook available but minimally implemented)
9. Implement memory storage (implemented through MemorySystem)

### Discord Integration Implementation
1. Set up Discord client using discord.py (DiscordAgentClient class)
2. Connect to Discord events (on_ready, on_message)
3. Implement mention detection and handling
4. Transform Discord messages to agent inputs
5. Process with Agent/Runner
6. Return responses to Discord channel
7. Maintain context with AgentMemory

### Instagram Integration Implementation
1. Set up Instagram client using Instagram Graph API (InstagramAgentClient class)
2. Implement FTP file upload functionality for media files
3. Create Instagram media container creation and publishing workflow
4. Implement status checking and publishing limit management
5. Add error handling and reconnection logic
6. Integrate with Agent/Runner for logging and context
7. Maintain context with AgentMemory

### Memory System Implementation
1. Define database schema with vector extensions
2. Implement core MemorySystem class for database operations
3. Create embedding generation functionality
4. Implement vector similarity search
5. Create specialized memory managers for different memory types
6. Implement memory hooks for runtime integration
7. Add memory CLI tool for management
8. Create memory cache for performance optimization
9. Implement integration tests for verification

### Tool Integration Implementation
1. Define abstract Tool interface
2. Implement tool registration system
3. Create validation framework
4. Add handler execution
5. Build tool discovery mechanism

### Client Integration Implementation
1. Build FastAPI endpoints
2. Implement WebSocket support
3. Add webhook capabilities
4. Set up authentication
5. Implement multi-client support in run_agent.py
6. Create client-specific hooks for each client type

## Known Challenges

### Memory Retrieval Optimization
The memory retrieval system for context-aware responses needs careful design:
- Balance between recall and precision in vector search
- Efficient vector operations for semantic search
- Caching strategies for frequent queries
- Handling of long-term vs. short-term memory
- Current implementation stores full conversation history in memory
- Tracking client source in memory objects for multi-client support
- Optimizing embedding generation to reduce API costs
- Implementing memory pruning and summarization for long conversations
- Handling very large memory stores efficiently
- Optimizing database indices for vector search

### Memory System Scaling
Scaling the memory system for production use:
- Partitioning memory storage by agent and time
- Implementing read replicas for memory retrieval
- Optimizing vector indices for large-scale similarity search
- Batching embedding generation for efficiency
- Implementing memory retention policies
- Managing memory storage growth over time
- Implementing memory backup and recovery procedures
- Handling memory migration and versioning

### Memory Privacy and Security
Ensuring proper memory privacy and security:
- Implementing access controls for memory retrieval
- User-specific memory isolation
- Configurable memory retention policies
- Consent management for memory storage
- Encryption of sensitive memory content
- Audit logging for memory access
- Compliance with data protection regulations
- Implementing memory export and deletion capabilities

### Discord Client Challenges
- Handling Discord API rate limits
- Maintaining stable connections for long periods
- Implementing proper reconnection logic
- Managing multiple agents in shared channels
- Processing mentions correctly in various message formats

### Instagram Client Challenges
- Managing Instagram Graph API publishing limits (25 posts per day)
- Handling the two-step posting process (create container, then publish)
- Optimizing FTP file uploads for media files
- Implementing proper error handling for failed uploads
- Managing container status checking and timeout handling
- Securing API credentials and FTP credentials
- Handling media file size and format restrictions

### Multi-Client Architecture Challenges
- Coordinating concurrent client operations
- Managing client-specific context and state
- Handling different types of content (text, media)
- Implementing client-specific error handling
- Balancing resource usage across clients
- Maintaining consistent agent behavior across clients

### Tool Security Constraints
Tools executed by agents need security boundaries:
- Input validation for tool parameters
- Resource limitations for tool execution
- Permissions model for tool access
- Auditing of tool usage
- Client-specific tool access controls

### Testing LLM-Based Systems
Testing deterministically with non-deterministic LLMs:
- Use of fixed test responses
- Mock LLM providers for testing
- Evaluation metrics for response quality
- Regression test suite for behavior

### Async Database Operations
Managing async database operations efficiently:
- Connection pooling with asyncio
- Transaction management in async context
- Vector search optimization
- Concurrent database operations

## Tool Usage

### Memory Bank
- Structured according to the hierarchy defined in the custom instructions
- Core files maintain relationships: projectbrief.md → productContext.md, systemPatterns.md, techContext.md → activeContext.md → progress.md
- Documentation in Markdown format used for all memory bank files
- Regular updates reflecting implementation progress

### Character Files
- Character definitions stored in JSON format in characters/
- Contains system prompt, bio, lore, communication style
- Used to generate comprehensive agent instructions
- Example: assistantbot.json for Discord and Instagram agent
- Client-specific context added to system prompt during initialization

### Memory System Tools
- Supabase for database backend
- PostgreSQL with vector extensions for semantic search
- OpenAI embeddings API for vector representation
- Memory CLI tool for management operations:
  - Listing memories with filtering
  - Clearing memories with confirmation
  - Testing similarity search
  - Initializing database schema
- Integration tests for verifying functionality

### Python Development Tools
- Anaconda environment named "carrier" with Python 3.9
- Black for code formatting
- isort for import sorting
- mypy for type checking
- flake8 for linting
- pre-commit hooks for automated checks
- python-dotenv for environment variable management

### API Tools
- Discord.py for Discord API integration
- Requests for Instagram Graph API calls
- FTPlib for FTP file uploads
- Aiohttp for asynchronous HTTP requests

### Database Tools
- PostgreSQL with vector extensions for semantic search
- Database migration tools for schema evolution
- Connection pooling for performance

## Decision Evolution

### Architecture Decisions
- Transition from Node.js (ElizaOS) to Python implementation
- Adoption of FastAPI over Express
- Use of Pydantic over Zod for validation
- SQLAlchemy ORM for database interactions
- asyncio for async processing
- Context managers for resource handling
- Multi-client architecture for platform flexibility

### Implementation Decisions
- Use of dataclasses for memory representation (AgentMemory)
- Command-pattern approach for agent hooks
- Discord.py's commands.Bot for Discord integration
- Instagram Graph API for Instagram integration
- FTP for media file uploads before Instagram posting
- Separation of character data from agent logic
- Runtime hooks to implement the processing pipeline stages
- Agent/Runner pattern for message processing
- Client-specific hooks for each client type
- Concurrent client operation in run_agent.py

### Memory System Decisions
- Supabase with PostgreSQL for database backend
- Vector extensions for semantic search
- OpenAI embeddings for vector representation
- Specialized memory managers for different memory types
- Memory hooks for runtime integration
- Memory CLI tool for management
- Memory cache for performance optimization
- Memory integration tests for verification
- Memory database schema with vector indices
- Memory retention based on agent, user, and room

### Database Decisions
- PostgreSQL with vector extension chosen over specialized vector databases
- Decision to use SQLAlchemy for ORM capabilities
- Choice of connection pooling approach
- Schema design with vector indices for similarity search
- Memory partitioning by type, agent, user, and room

## Notes
The Carrier project takes strong inspiration from ElizaOS but adapts its patterns to leverage Python's strengths. The core runtime loop remains the same conceptually, but the implementation details differ to align with Python's ecosystem and paradigms.

The current implementation demonstrates the 7-step runtime loop with hooks for each stage, using the Agent class for basic agent representation and the Runner for processing. The Discord and Instagram integrations serve as practical applications of the framework, showing how agents can interact through different channels while maintaining a consistent processing approach.

The multi-client architecture demonstrates the flexibility of the framework, allowing agents to interact through different channels (Discord for conversational interactions, Instagram for media posting) while sharing the same core processing pipeline. Each client implementation follows the same pattern of hooks and event handling, but with client-specific adaptations for the unique requirements of each platform.

The memory system extends the framework's capabilities by providing persistent storage and retrieval of interactions, enabling context-aware responses across multiple conversations and platforms. The vector-based approach allows for semantic search, retrieving memories based on content similarity rather than just exact matches or timestamps.

Future development will focus on enhancing the memory system, improving tool integration, refining the agent runtime components for more sophisticated processing and response generation, and expanding the multi-client architecture to support additional platforms and interaction types.
