# Carrier Project Intelligence

This file serves as a learning journal for the Carrier project, capturing important patterns, preferences, and project intelligence that help work more effectively. This document will evolve as we discover and document key insights about the project.

## Project Patterns

### Agent Runtime Loop Pattern
The core pattern for the Carrier project is the 7-step runtime loop:
1. **Initialization**: Set up the agent with personality, actions, providers, services
2. **Message Reception**: Receive messages from various clients
3. **Message Processing**: Process through decision pipeline
4. **Response Generation**: Generate responses using LLMs
5. **Action Execution**: Execute any needed actions
6. **Evaluation**: Assess response quality
7. **Memory Storage**: Store interactions for context

This pattern is the foundation of the agent architecture and is now implemented in both discord_agent.py and tifa_agent.py through runtime hooks and the Agent/Runner classes.

### Runtime Hooks Implementation Pattern
The Carrier framework uses a hooks pattern to implement the runtime loop stages:
```python
class DiscordHooks(RunHooks):
    async def on_agent_start(self, context, agent) -> None:
        # Step 3: Message Processing pipeline begins
        
    async def on_tool_start(self, context, agent, tool) -> None:
        # Step 5: Action Execution begins
        
    async def on_tool_end(self, context, agent, tool, result) -> None:
        # Step 5: Action Execution completes
        
    async def on_agent_end(self, context, agent, output) -> None:
        # Step 6: Evaluation and Step 7: Memory Storage complete
```

### Component Responsibility Pattern
Each component in the system has clear, single responsibilities:
- **Agent Runtime**: Overall coordination
- **Message Manager**: Message processing
- **State Manager**: Context composition
- **Action Manager**: Tool execution
- **Evaluation System**: Response assessment
- **Memory System**: Interaction storage
- **Provider System**: LLM integration

This separation of concerns ensures that components can evolve independently.

### Async Processing Pattern
The Python implementation leans heavily on async/await:
- Use `asyncio` for concurrent operations
- Implement non-blocking database operations
- Design event-driven message processing

## User Preferences

### Python Implementation Style
- Use of Pydantic for data validation and type hints
- FastAPI for web endpoints (REST/WebSocket)
- Modern Python features (3.9+) including type hints
- SQLAlchemy for database operations
- Preference for async programming model

### Documentation Approach
- Document architecture decisions thoroughly
- Maintain clear component boundaries
- Use mermaid diagrams for visualizing relationships
- Document data flows between components

## Implementation Paths

### Core Runtime Implementation
1. Define data models with Pydantic
2. Implement database schema
3. Create AgentRuntime class (partially implemented through Agent/Runner classes)
4. Build message processing pipeline (implemented through RunHooks)
5. Implement state composition (partial through AgentMemory)
6. Add response generation (implemented through Runner.run)
7. Set up action execution (tool execution framework started)
8. Add evaluation system (hook available but minimally implemented)
9. Implement memory storage (basic implementation with AgentMemory dataclass)

### Discord Integration Implementation
1. Set up Discord client using discord.py (DiscordAgentClient class)
2. Connect to Discord events (on_ready, on_message)
3. Implement mention detection and handling
4. Transform Discord messages to agent inputs
5. Process with Agent/Runner
6. Return responses to Discord channel
7. Maintain context with AgentMemory

### Tool Integration Implementation
1. Define abstract Tool interface
2. Implement tool registration system
3. Create validation framework
4. Add handler execution
5. Build tool discovery mechanism

### Client Integration Implementation
1. Build FastAPI endpoints
2. Implement WebSocket support
3. Add webhook capabilities
4. Set up authentication

## Known Challenges

### Memory Retrieval Optimization
The memory retrieval system for context-aware responses needs careful design:
- Balance between recall and precision
- Efficient vector operations for semantic search
- Caching strategies for frequent queries
- Handling of long-term vs. short-term memory
- Current implementation stores full conversation history in memory

### Discord Client Challenges
- Handling Discord API rate limits
- Maintaining stable connections for long periods
- Implementing proper reconnection logic
- Managing multiple agents in shared channels
- Processing mentions correctly in various message formats

### Tool Security Constraints
Tools executed by agents need security boundaries:
- Input validation for tool parameters
- Resource limitations for tool execution
- Permissions model for tool access
- Auditing of tool usage

### Testing LLM-Based Systems
Testing deterministically with non-deterministic LLMs:
- Use of fixed test responses
- Mock LLM providers for testing
- Evaluation metrics for response quality
- Regression test suite for behavior

### Async Database Operations
Managing async database operations efficiently:
- Connection pooling with asyncio
- Transaction management in async context
- Vector search optimization
- Concurrent database operations

## Tool Usage

### Memory Bank
- Structured according to the hierarchy defined in the custom instructions
- Core files maintain relationships: projectbrief.md → productContext.md, systemPatterns.md, techContext.md → activeContext.md → progress.md
- Documentation in Markdown format used for all memory bank files
- Regular updates reflecting implementation progress

### Character Files
- Character definitions stored in JSON format in characters/
- Contains system prompt, bio, lore, communication style
- Used to generate comprehensive agent instructions
- Example: assistantbot.json for Discord assistant agent

### Python Development Tools
- Anaconda environment named "carrier" with Python 3.9
- Black for code formatting
- isort for import sorting
- mypy for type checking
- flake8 for linting
- pre-commit hooks for automated checks

### Database Tools
- PostgreSQL with vector extensions for semantic search
- Database migration tools for schema evolution
- Connection pooling for performance

## Decision Evolution

### Architecture Decisions
- Transition from Node.js (ElizaOS) to Python implementation
- Adoption of FastAPI over Express
- Use of Pydantic over Zod for validation
- SQLAlchemy ORM for database interactions
- asyncio for async processing
- Context managers for resource handling

### Implementation Decisions
- Use of dataclasses for memory representation (AgentMemory)
- Command-pattern approach for agent hooks
- Discord.py's commands.Bot for Discord integration
- Separation of character data from agent logic
- Runtime hooks to implement the processing pipeline stages
- Agent/Runner pattern for message processing

### Database Decisions
- PostgreSQL with vector extension chosen over specialized vector databases
- Decision to use SQLAlchemy for ORM capabilities
- Choice of connection pooling approach

## Notes
The Carrier project takes strong inspiration from ElizaOS but adapts its patterns to leverage Python's strengths. The core runtime loop remains the same conceptually, but the implementation details differ to align with Python's ecosystem and paradigms.

The current implementation demonstrates the 7-step runtime loop with hooks for each stage, using the Agent class for basic agent representation and the Runner for processing. The Discord integration serves as a practical application of the framework, showing how agents can interact in real-time chat environments.

Future development will focus on enhancing the memory system, improving tool integration, and refining the agent runtime components for more sophisticated processing and response generation.
