# Carrier Project Intelligence

This file serves as a learning journal for the Carrier project, capturing important patterns, preferences, and project intelligence that help work more effectively. This document will evolve as we discover and document key insights about the project.

## Project Patterns

### Agent Runtime Loop Pattern
The core pattern for the Carrier project is the 7-step runtime loop:
1. **Initialization**: Set up the agent with personality, actions, providers, services
2. **Message Reception**: Receive messages from various clients
3. **Message Processing**: Process through decision pipeline
4. **Response Generation**: Generate responses using LLMs
5. **Action Execution**: Execute any needed actions
6. **Evaluation**: Assess response quality
7. **Memory Storage**: Store interactions for context

This pattern is the foundation of the agent architecture and is now implemented in both discord_agent.py and tifa_agent.py through runtime hooks and the Agent/Runner classes.

### Runtime Hooks Implementation Pattern
The Carrier framework uses a hooks pattern to implement the runtime loop stages:
```python
class DiscordHooks(RunHooks):
    async def on_agent_start(self, context, agent) -> None:
        # Step 3: Message Processing pipeline begins

    async def on_tool_start(self, context, agent, tool) -> None:
        # Step 5: Action Execution begins

    async def on_tool_end(self, context, agent, tool, result) -> None:
        # Step 5: Action Execution completes

    async def on_agent_end(self, context, agent, output) -> None:
        # Step 6: Evaluation and Step 7: Memory Storage complete
```

### Component Responsibility Pattern
Each component in the system has clear, single responsibilities:
- **Agent Runtime**: Overall coordination
- **Message Manager**: Message processing
- **State Manager**: Context composition
- **Action Manager**: Tool execution
- **Evaluation System**: Response assessment
- **Memory System**: Interaction storage
- **Provider System**: LLM integration

This separation of concerns ensures that components can evolve independently.

### Async Processing Pattern
The Python implementation leans heavily on async/await:
- Use `asyncio` for concurrent operations
- Implement non-blocking database operations
- Design event-driven message processing

### Memory System Pattern
The memory system follows a layered architecture:
- **Core MemorySystem**: Handles database operations and embedding generation
- **Specialized Memory Managers**: Provide tailored interfaces for different memory types
- **Memory Hooks**: Integrate memory with agent runtime
- **Memory Cache**: Optimizes performance for frequently accessed data

```python
# Core MemorySystem for database operations
class MemorySystem:
    async def store_memory(self, content, memory_type, user_id, room_id, agent_id, metadata=None):
        # Generate embedding and store in database

    async def retrieve_similar(self, query, threshold=0.7, limit=10, memory_type=None):
        # Perform vector similarity search

# Specialized memory manager for messages
class MessageManager:
    async def create_memory(self, message):
        # Create a message memory

    async def get_conversation(self, user_id, room_id, agent_id, limit=20):
        # Get conversation history

# Memory hooks for runtime integration
class MemoryContextHooks:
    async def on_agent_start(self, context, agent):
        # Add conversation history to system prompt
```

### Vector Similarity Search Pattern
The memory system uses vector embeddings for semantic search:
- Generate embeddings for all stored memories
- Generate embedding for search query
- Perform vector similarity search using cosine similarity
- Return memories above similarity threshold

```python
# Vector similarity search in PostgreSQL
"""
SELECT
    m.id,
    m.type,
    m.content,
    m.embedding,
    m.user_id,
    m.room_id,
    m.agent_id,
    m.metadata,
    m.created_at,
    1 - (m.embedding <=> $1) as similarity
FROM
    %I.memories m
WHERE
    m.embedding IS NOT NULL AND
    1 - (m.embedding <=> $1) > $2
ORDER BY
    m.embedding <=> $1
LIMIT $3
"""
```

### Memory Manager Pattern
Specialized memory managers for different memory types:
- **MessageManager**: Conversation messages
- **DescriptionManager**: User descriptions
- **LoreManager**: Agent background information
- **DocumentsManager**: Large documents
- **KnowledgeManager**: Searchable knowledge fragments
- **RAGKnowledgeManager**: Retrieval-augmented generation

Each manager extends BaseMemoryManager and provides specialized methods for its memory type.

### MCP Integration Pattern (New)
- **Central Configuration**: `config/mcp_servers.json` defines all servers (stdio/sse) with parameters. Keys are unique server names.
- **Character Configuration**: `characters/*.json` lists required server *names* under `mcp_servers`.
- **Centralized Management**: `run_agents.py` identifies unique required servers, starts them concurrently using `AsyncExitStack`, manages lifecycles, and maps active instances by name.
- **Environment Variables**: API keys/secrets for MCP servers are loaded from `.env` in `run_agents.py` and injected into the server's environment during startup.
- **Agent Initialization**: `initialize_agent` receives active server instances, fetches MCP tools via `server.list_tools()`, combines with built-in tools for the system prompt, and passes active servers + built-in tools to the `Agent` constructor.
- **Tool Introspection**: `list_available_tools` built-in tool allows agents to list all their tools (built-in + MCP).

## User Preferences

### Python Implementation Style
- Use of Pydantic for data validation and type hints
- FastAPI for web endpoints (REST/WebSocket)
- Modern Python features (3.9+) including type hints
- SQLAlchemy for database operations
- Preference for async programming model

### Documentation Approach
- Document architecture decisions thoroughly
- Maintain clear component boundaries
- Use mermaid diagrams for visualizing relationships
- Document data flows between components

### Memory System Preferences
- Supabase for database backend
- PostgreSQL with vector extensions for semantic search
- OpenAI embeddings for vector representation
- Specialized memory managers for different memory types
- Memory hooks for runtime integration
- CLI tools for memory management

## Implementation Paths

### Core Runtime Implementation
1. Define data models with Pydantic
2. Implement database schema
3. Create AgentRuntime class (partially implemented through Agent/Runner classes)
4. Build message processing pipeline (implemented through RunHooks)
5. Implement state composition (partial through AgentMemory)
6. Add response generation (implemented through Runner.run)
7. Set up action execution (tool execution framework started)
8. Add evaluation system (hook available but minimally implemented)
9. Implement memory storage (implemented through MemorySystem)

### Discord Integration Implementation
1. Set up Discord client using discord.py (DiscordAgentClient class)
2. Connect to Discord events (on_ready, on_message)
3. Implement mention detection and handling
4. Transform Discord messages to agent inputs
5. Process with Agent/Runner
6. Return responses to Discord channel
7. Maintain context with AgentMemory

### Instagram Integration Implementation
1. Set up Instagram client using Instagram Graph API (InstagramAgentClient class)
2. Implement FTP file upload functionality for media files
3. Create Instagram media container creation and publishing workflow
4. Implement status checking and publishing limit management
5. Add error handling and reconnection logic
6. Integrate with Agent/Runner for logging and context
7. Maintain context with AgentMemory

### Memory System Implementation
1. Define database schema with vector extensions
2. Implement core MemorySystem class for database operations
3. Create embedding generation functionality
4. Implement vector similarity search
5. Create specialized memory managers for different memory types
6. Implement memory hooks for runtime integration
7. Add memory CLI tool for management
8. Create memory cache for performance optimization
9. Implement integration tests for verification

### Tool Integration Implementation
1. Define abstract Tool interface
2. Implement tool registration system
3. Create validation framework
4. Add handler execution
5. Build tool discovery mechanism
6. Implement `list_available_tools` tool.

### Client Integration Implementation
1. Build FastAPI endpoints
2. Implement WebSocket support
3. Add webhook capabilities
4. Set up authentication
5. Implement multi-client support in run_agent.py
6. Create client-specific hooks for each client type

### MCP Integration Implementation (New)
1. Create `config/mcp_servers.json` with server definitions.
2. Update character files (`characters/*.json`) to list required server names.
3. Refactor `run_agents.py` for centralized server management using `AsyncExitStack`.
4. Update `initialize_agent` to fetch MCP tools and configure `Agent`.
5. Update `build_system_prompt` to include MCP tools.
6. Add `list_available_tools` to `src/carrier/tools.py`.
7. Update `CarrierAgent` class.
8. Create `tests/test_mcp_integration.py`.

## Known Challenges

### Memory Retrieval Optimization
The memory retrieval system for context-aware responses needs careful design:
- Balance between recall and precision in vector search
- Efficient vector operations for semantic search
- Caching strategies for frequent queries
- Handling of long-term vs. short-term memory
- Current implementation stores full conversation history in memory
- Tracking client source in memory objects for multi-client support
- Optimizing embedding generation to reduce API costs
- Implementing memory pruning and summarization for long conversations
- Handling very large memory stores efficiently
- Optimizing database indices for vector search

### Memory System Scaling
Scaling the memory system for production use:
- Partitioning memory storage by agent and time
- Implementing read replicas for memory retrieval
- Optimizing vector indices for large-scale similarity search
- Batching embedding generation for efficiency
- Implementing memory retention policies
- Managing memory storage growth over time
- Implementing memory backup and recovery procedures
- Handling memory migration and versioning

### Memory Privacy and Security
Ensuring proper memory privacy and security:
- Implementing access controls for memory retrieval
- User-specific memory isolation
- Configurable memory retention policies
- Consent management for memory storage
- Encryption of sensitive memory content
- Audit logging for memory access
- Compliance with data protection regulations
- Implementing memory export and deletion capabilities

### Discord Client Challenges
- Handling Discord API rate limits
- Maintaining stable connections for long periods
- Implementing proper reconnection logic
- Managing multiple agents in shared channels
- Processing mentions correctly in various message formats
- Using numeric channel IDs (snowflakes) instead of channel names
- Configuring channel settings through character files rather than hardcoding

### Instagram Client Challenges
- Managing Instagram Graph API publishing limits (25 posts per day)
- Handling the two-step posting process (create container, then publish)
- Optimizing FTP file uploads for media files
- Implementing proper error handling for failed uploads
- Managing container status checking and timeout handling
- Securing API credentials and FTP credentials
- Handling media file size and format restrictions

### Multi-Client Architecture Challenges
- Coordinating concurrent client operations
- Managing client-specific context and state
- Handling different types of content (text, media)
- Implementing client-specific error handling
- Balancing resource usage across clients
- Maintaining consistent agent behavior across clients

### Tool Security Constraints
Tools executed by agents need security boundaries:
- Input validation for tool parameters
- Resource limitations for tool execution
- Permissions model for tool access
- Auditing of tool usage
- Client-specific tool access controls
- **MCP Server Security**: Ensure API keys/tokens needed by MCP servers are loaded securely from environment variables (`.env`) and passed via the `env` parameter during server startup in `run_agents.py`, not stored directly in `config/mcp_servers.json`.

### Testing LLM-Based Systems
Testing deterministically with non-deterministic LLMs:
- Use of fixed test responses
- Mock LLM providers for testing
- Evaluation metrics for response quality
- Regression test suite for behavior

### Async Database Operations
Managing async database operations efficiently:
- Connection pooling with asyncio
- Transaction management in async context
- Vector search optimization
- Concurrent database operations

### MCP Integration Challenges (New)
- Robust error handling for MCP server startup failures in `run_agents.py`.
- Handling errors during `server.list_tools()` calls.
- Ensuring compatibility with various MCP server implementations and versions.
- Managing resource consumption of multiple concurrent MCP server processes.
- Verifying secure handling of environment variables passed to servers.

## Tool Usage

### Memory Bank
- Structured according to the hierarchy defined in the custom instructions
- Core files maintain relationships: projectbrief.md → productContext.md, systemPatterns.md, techContext.md → activeContext.md → progress.md
- Documentation in Markdown format used for all memory bank files
- Regular updates reflecting implementation progress

### Character Files
- Character definitions stored in JSON format in `characters/`.
- Contains system prompt, bio, lore, communication style, built-in `tools` (list of names), and required `mcp_servers` (list of names).
- Used to generate comprehensive agent instructions.
- Example: `assistantbot.json`.

### MCP Configuration
- Central configuration stored in `config/mcp_servers.json`.
- Defines connection details (`command`, `args`, `env`, `url`, etc.) for each named MCP server.

### Memory System Tools
- Supabase for database backend
- PostgreSQL with vector extensions for semantic search
- OpenAI embeddings API for vector representation
- Memory CLI tool for management operations:
  - Listing memories with filtering
  - Clearing memories with confirmation
  - Testing similarity search
  - Initializing database schema
- Integration tests for verifying functionality (`tests/test_memory.py`).

### MCP Integration Tools
- OpenAI Agent SDK classes: `MCPServerStdio`, `MCPServerSse`.
- `contextlib.AsyncExitStack` for managing server lifecycles in `run_agents.py`.
- `list_available_tools` built-in tool for introspection.
- Integration tests (`tests/test_mcp_integration.py`).

### Python Development Tools
- Anaconda environment named "carrier" with Python 3.9
- Black for code formatting
- isort for import sorting
- mypy for type checking
- flake8 for linting
- pre-commit hooks for automated checks
- python-dotenv for environment variable management

### API Tools
- Discord.py for Discord API integration
- Requests for Instagram Graph API calls
- FTPlib for FTP file uploads
- Aiohttp for asynchronous HTTP requests

### Database Tools
- PostgreSQL with vector extensions for semantic search
- Database migration tools for schema evolution
- Connection pooling for performance

## Decision Evolution

### Architecture Decisions
- Transition from Node.js (ElizaOS) to Python implementation
- Adoption of FastAPI over Express
- Use of Pydantic over Zod for validation
- SQLAlchemy ORM for database interactions
- asyncio for async processing
- Context managers for resource handling
- Multi-client architecture for platform flexibility

### Implementation Decisions
- Use of dataclasses for memory representation (AgentMemory)
- Command-pattern approach for agent hooks
- Discord.py's commands.Bot for Discord integration
- Instagram Graph API for Instagram integration
- FTP for media file uploads before Instagram posting
- Separation of character data from agent logic
- Runtime hooks to implement the processing pipeline stages
- Agent/Runner pattern for message processing
- Client-specific hooks for each client type
- Concurrent client operation in run_agent.py
- OpenAI Agents SDK parameter naming conventions (starting_agent instead of agent)
- Configuration-driven approach for client settings via character files

### Memory System Decisions
- Supabase with PostgreSQL for database backend
- Vector extensions for semantic search
- OpenAI embeddings for vector representation
- Specialized memory managers for different memory types
- Memory hooks for runtime integration
- Memory CLI tool for management
- Memory cache for performance optimization
- Memory integration tests for verification
- Memory database schema with vector indices
- Memory retention based on agent, user, and room

### Database Decisions
- PostgreSQL with vector extension chosen over specialized vector databases
- Decision to use SQLAlchemy for ORM capabilities
- Choice of connection pooling approach
- Schema design with vector indices for similarity search
- Memory partitioning by type, agent, user, and room

### MCP Integration Decisions (New)
- Centralized server configuration in `config/mcp_servers.json`.
- Character files specify required servers by name.
- Centralized server lifecycle management in `run_agents.py` using `AsyncExitStack`.
- API keys loaded from `.env` and injected into server environment.
- `list_available_tools` added for introspection.

## Notes
The Carrier project takes strong inspiration from ElizaOS but adapts its patterns to leverage Python's strengths. The core runtime loop remains the same conceptually, but the implementation details differ to align with Python's ecosystem and paradigms.

The current implementation demonstrates the 7-step runtime loop with hooks for each stage, using the Agent class for basic agent representation and the Runner for processing. The Discord and Instagram integrations serve as practical applications of the framework, showing how agents can interact through different channels while maintaining a consistent processing approach.

The multi-client architecture demonstrates the flexibility of the framework, allowing agents to interact through different channels (Discord for conversational interactions, Instagram for media posting) while sharing the same core processing pipeline. Each client implementation follows the same pattern of hooks and event handling, but with client-specific adaptations for the unique requirements of each platform.

The memory system extends the framework's capabilities by providing persistent storage and retrieval of interactions, enabling context-aware responses across multiple conversations and platforms. The vector-based approach allows for semantic search, retrieving memories based on content similarity rather than just exact matches or timestamps.

The MCP integration adds the ability to leverage external tools defined in a central configuration, managed efficiently during runtime.

Future development will focus on enhancing the memory system, refining the MCP integration (testing, error handling), improving tool integration, refining the agent runtime components for more sophisticated processing and response generation, and expanding the multi-client architecture to support additional platforms and interaction types.

## Additional notes from me
/src/agents is for the public repository OpenAI Agent SDK files. Custom code for this Carrier project should go in /src/carrier. So DO NOT modify any files under /src/agents since they will be overwritten when the Agent SDK code is pulled for updates.
Do not edit the .env file directly. Always prompt me to do so manually.
Always use your MCP tools if appropriate.
Refer to the OpenAI Agent SDK documentation when implementing new functionality: https://openai.github.io/openai-agents-python/